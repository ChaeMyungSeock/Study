Onehotencoding
단위행렬 느낌의 인코딩 원하는 인덱스의 값들을 제외하고는 필요없음

mnist =>숫자 이미지를 불러와서 분석해볼거에요~

from keras.datasets import mnist 			# 케라스에 있는 데이터시트의 mnist를 가져올거야!

(x_train, y_train), (x_test, y_test) = mnist.load_data()	# mnist의 데이터를 불러와서 (x_train, y_train), (x_test, y_test) 로 나눠줄게!

print(x_train.shape)    # (60000, 28, 28) batch_size = 60000, 28 * 28 이미지
print(x_test.shape)     # (10000, 28, 28) batch_size = 10000, 28 * 28
print(y_train.shape)    # (60000,)  inputdim = 1
print(y_test.shape)     # (10000,)

plt.imshow(x_train[8000], 'gray')		# 그레이새캬 색으로 x_train[8000] 그려줄게!
# plt.show()				# 보여줘봐


원 핫 코딩
from keras.utils import np_utils
from keras.utils import to_categorical
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# np_utils.to_categorical(클래스, 클래스의 개수) 함수
# 정수 숫자를 -> [0,0,1,0,0,0]  처럼 바꿔서 구분하는 것


y = np.array([1,2,3,4,5,1,2,3,4,5])
y = y.reshape(10,1)
from sklearn.preprocessing import OneHotEncoder
aaa = OneHotEncoder()
aaa.fit(y)
y = aaa.transform(y).toarray()

print(y)
print(y.shape)

[[1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]]
(10, 5)


x_train = x_train.reshape(60000, 28, 28, 1).astype('float32') / 255		# 최대값을 알고 있기에 할 수 있는 minmax정규화
x_test = x_test.reshape(10000, 28, 28, 1).astype('float32') / 255		# .astype('float32')은 파이썬에서 자동으로 int / int => float형을 지원하기 때문에 상관 없음

# cnn모델을 구사아하기 위해서 bach_size 행 열 채널

model.add(Conv2D(100, (3,3), input_shape = (28,28,1)))			# (3,3) 보통 (3,3)을 주로 쓰며 홀수를 사용함 1,3,5,7 최대 7까지 사용하며 5부터는 너무 과하다고 생각하는 경향, 겹치는 데이터는 많아지지만 (속도 저하)
padding = 'same' 을 사용하면 패딩을 입듯이 데이터에 default data가 덧 씌워져서 이미지가 상대적으로 덜 훈련받아 (상대적으로)손실되는 것을 막아줌 하지만 strides로 자르는 index를 추가해주면 잘림

model.add(MaxPool2D(pool_size=2)) # MaxPool 자원소모 x Conv2D + MaxPool2D 한 layer라고 생각하는게 편함


MaxPool2D
컨볼루션 레이어의 출력 이미지에서 주요값만 뽑아 크기가 작은 출력 영상을 만듭니다. 이것은 지역적인 사소한 변화가 영향을 미치지 않도록 합니다.
일정 영역에서 가장 높은 값들만 뽑아서  작은 변화에는 큰 영향을 미치지 않도록
이 레이어는 영상의 작은 변화라던지 사소한 움직임이 특징을 추출할 때 크게 영향을 미치지 않도록 합니다. 영상 내에 특징이 세 개가 있다고 가정했을 때, 아래 그림에서 
첫 번째 영상을 기준으로 두 번째 영상은 오른쪽으로 이동하였고, 세 번째 영상은 약간 비틀어 졌고, 네 번째 영상은 조금 확대되었지만, 맥스풀링한 결과는 모두 동일합니다. 
얼굴 인식 문제를 예를 들면, 맥스풀링의 역할은 사람마다 눈, 코, 입 위치가 조금씩 다른데 이러한 차이가 사람이라고 인식하는 데 있어서는 큰 영향을 미치지 않게 합니다.
(출처 : https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)


▶ softmax 함수란?

뉴런의 출력값에 대하여 class 분류를 위하여 마지막 단계에서 출력값에 대한 정규화를 해주는 함수이다.

인물 사진을 예로 들어 보겠다.

사진속 인물이 지금 슬픈 표정인지, 웃는 표정인지, 화난 표정인지 확률적으로 수치화한다고 했을때,

슬픔 (11%), 웃음 (29%), 화남(60%) 화같이 확률적 classification 을 할 때 용이하다.

소프트맥스 함수의 특징은 결과물의 수치의 합은 언제나 1.0 이다.


model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics=['acc'])

RMSProp 옵티마이저.

RMSProp을 사용할 때는 학습률을 제외한 모든 인자의 기본값을 사용하는 것이 권장됩니다.

일반적으로 순환 신경망(Recurrent Neural Networks)의 옵티마이저로 많이 사용됩니다.

categorical_crossentropy
keras.losses.categorical_crossentropy(y_true, y_pred)
Note: 손실 함수 categorical_crossentropy의 경우 사용되는 타겟들은 범주 형식(categorical format)을 따라야 합니다. 예를 들어 10개의 클래스(범주) 중 하나에 속하는 데이터에
 대하여 각 샘플은 타겟 클래스에 해당하는 하나의 인덱스만 1의 값을 가지고 이외의 값들은 모두 0이어야 합니다. Keras의 기능인 to_categorical을 통해 
정수형 타겟(integer target)을 범주형 타겟(categorical target)으로 변환할 수 있습니다.


binary_crossentropy
keras.losses.binary_crossentropy(y_true, y_pred)  # 이중분류 할 때 사용

y_predict = np.argmax(y_predict,axis=1) 

numpy.argmax - 다차원 배열의 경우에 차원에 따라 가장 큰 값의 인덱스들을 반환해주는 함수

axis가 0 이면 열, axis가 1이면 행. 2이면 면
참고로 argmax는 가장 큰 값의 인덱스 값을 반환한다.

x_train = x_train / 255
x_test = x_test / 255		# 넘파이라 ndarray에 그냥 가능
