from keras.layers import Dense, Input #DNN구조에 가장 기본이 되는 Dense layer
Dense은 가장 기본적인 구조이나 RNN, CNN에서의 다차원의 데이터를 받기 위해서는 shape가 더 편할 것이다
shape의 경우(3,) 이런식으로 구성이 되는데 행을 무시하고 열을 data 칼럼의 갯수를 신경쓴 것
추후 data feature에 대한 부분도 신경써야하는데 이는 추후 정리 => data를 받아올 때 data 칼럼의 갯수를 신경쓴다!!


from keras.models import Sequential, Model
모델구성을 Sequential의 단일구조가 아닌 함수형모델로 형성해줌, Sequential의 경우도 함수형처럼 앙상블 할 수 있다고는 하지만
확인해봐야함. 함수의 경우 Sequential보다는 유연하고 다른 모델과의 앙상블이 자유로움 but 그 앙상블이 모델의 최적화를 보장하진
않는다. 보통의 경우의 대회에서 Sequential로 모델링이 되는 경우가 대다수임


앙상블
x1 = np.array([range(1,101), range(311, 411), range(100)])
x1= x1.transpose()

데이터를 transpose를 통해서 3행 100열의 데이터를 100행 3열의 데이터로 형변환을 해줘야 한다. 여기서의 열의 경우 데이터의 종류를
뜻함 100행의 데이터가 하나의 열로 1칼럼이라고 생각하면 된다.

다:다 앙상블 모델
data set에 맞게 transpose해주고 train_test_split를 해준다 => 데이터 제한없이 한번에 해줄 수도 있음
Input함수를 통해 shape = (3,) 데이터 input 차원을 맞춰줌 name='start'를 통해서 layer에 이름을 지정해줘서 내가 보기에
더 편하게 바꿔서 알아보기 쉽게 할 수 있음 x 칼럼이 여러개이면 input도 그에 맞춰서 늘어남. y칼럼이 늘어나면 output도
그에 맞춰서 늘어남

2개의 input이 있다고 가정할 때 함수형으로 각자 모델링을 이어가다가 
merge1 = concatenate([output1, output2])로 layer를 합쳐줌 여기서 output이 몇개이냐에 따라서 나눠짐
model1 = Dense(110)(model1)
output3 = Dense(31)(model1)
output4 = Dense(32)(model1)
이번에 경우 output 칼럼이 2개이므로 한개의 layer에서 2개로 갈라서 output이 나옴
model1 = Model(inputs = [input1, input2], outputs = [output3_1, output4_1]) Model의 경우도 list로 받아준다
뒤로 이어지는 model1.fit이나 model1.evaluate 또한 list로 값을 받는다
=====> evaluate에서 loss, mse를 구할 수 있는데 여기서 loss의 경우 총 loss값과 각각의 loss들의 값을 return해줌
mse의 값들은 각각의 mse값들을 반환해줌

그리고 밑의 함수를 통해서 각각의 RMSE를 구할 수 있다. 하지만 만약에 서로간의 layer로 인해서 RMSE값을 합쳐야 하거나
평균을 구해야만 한다면 먼저 MSE의 평균을 구한뒤에 루트를 씌우면 된다.
def RMSE(y_test ,y_predict1):
    return np.sqrt(mean_squared_error(y1_test,y1_predict))
RMSE1 = RMSE(y1_test,y1_predict)
RMSE2 = RMSE(y2_test,y2_predict)

같은 방법으로 밑에는 각각의 R2값을 구하는 방법이다.
from sklearn.metrics import r2_score
r2_1 = r2_score(y1_test, y1_predict)
r2_2 = r2_score(y2_test, y2_predict)
서로 더해주고 더해준 갯수만큼 나눠주면 됨

R2의 경우 수학적인 모델이 어떻게 구성되어서 구해지는지 아직 잘 모르기 때문에 나중에 정리하면서 다시 수정할 계획

