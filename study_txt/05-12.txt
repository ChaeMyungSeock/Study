y = w(가중치)x + b(bias)

import numpy as np #numpy를 가져와서 np로 사용하겠다
#데이터 생성
from keras.models import Sequential # 순차적인 모델로 모델링
from keras.layers import Dense # layer를 Dense로 사용하겠다 , 대문자를 사용하는경우는 클래스를 의미

x_train = np.array([2,3,4,5,6,7,8,9,10,11])
y_train = np.array([4,9,16,25,36,49,64,81,100,121])
x_test = np.array([10,11,12,13,14,15,16,17,18,19])
y_test = np.array([100,121,144,169,196,225,256,289,324,361])

model = Sequential()
model.add(Dense(600, input_dim=1, activation='relu')) #모델.add 담을 쌓겠다, input_dim 인풋디멘션에 노드가 1(+bias 1개) output => 600개
model.add(Dense(150)) # 위에 output노드가 여기선 input노드 이므로 생략 
model.add(Dense(170))
model.add(Dense(160))
model.add(Dense(1)) # 출력값이 1개이므로 output 노드는 1개만 필요하다

model.summary() # 이 함수를 통해서 파라미터가 몇개로 어떻게 구동하는지 대략적으로 알 수 있다.

model.compile(loss='mse', optimizer='adam', metrics=['mse'])

# loss 손실함수는 평균 제곱법을 쓰겠다.
# 최적화 함수는 'adam' 옵티마이저를 쓰겠다.
# 어떤방식 => accuracy(정확도), mse 제곱근 오차방식으로 판정하겠다.

model.fit(x_train,y_train, epochs=1000,validation_data=(x_train,y_train)) # validation_data 사용하는 이유는 "모델의 성능을 평가하기 위해서"
# 또한 validation set은 여러 모델 중에서 최종 모델을 선정하기 위한 성능 평가에 관여한다
loss, acc = model.evaluate(x_test,y_test)
#batchsize를 지정해주지 안했음에도 불구하고 값이 산출되는 이유는 batchsize의 default값이 32이기 때문

print("loss : ",loss)
print("acc : ", acc)

y_predict = model.predict(x_test)
print("결과물 : \n", y_predict)



# RMSE 구하기
from sklearn.metrics import mean_squared_error
def RMSE(y_test, y_predict):
	return np.sqrt(mean_squared_error(y_test, y_predict))
print("RMSE : ", RMSE(y_test, y_predict))

# RMSE(평균 제곱근 오차, Root Mean Squared Error)는 회귀 분석을 평가할 때 가장 많이 쓰는 지표
# 원래 데이터에서 평균을 뺀 값을 제곱하여 모두 더한 뒤 전체 개수로 나눈 값에 루트를 씌운것 (낮을 수록 정밀도가 높음!!)
# 이는 수치일 뿐 %으로 생각하면 오류다. 0.97도 나오지만 60000도 나올 수 있음

# R2 (결정계수) => Max = 1 대략 0~1 만약, 0.73이런시긍로 값이 나온다면 73%의 설명력을 가진다고 해석이 가능
# R2 구하기
from sklearn.metrics import r2_score
r2_y_predict = r2_score(y_test, y_predict)
print("R2 :  ", r2_y_predict)

*하이퍼파라미터 튜닝*
1. node 및 layer를 조정
2. epochs를 조정
3. 데이터 숫자를 늘림
